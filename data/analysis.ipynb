{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511581aa",
   "metadata": {},
   "source": [
    "### Natural break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24cf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "melted_df = pd.read_csv('../data/traffic/adt_data.csv')\n",
    "melted_df = melted_df.dropna(subset=['ADT'])\n",
    "melted_df = melted_df[melted_df['rank'] <= 25] # focus on top 25 busiest roads\n",
    "\n",
    "# 1. JENKS NATURAL BREAKS (Fisher-Jenks algorithm)\n",
    "# Best for finding natural groupings in data\n",
    "def jenks_breaks(data, n_classes):\n",
    "    \"\"\"\n",
    "    Compute Jenks Natural Breaks classification\n",
    "    \"\"\"\n",
    "    data = np.array(sorted(data))\n",
    "    n = len(data)\n",
    "    \n",
    "    # Initialize matrices\n",
    "    mat1 = np.zeros((n, n_classes))\n",
    "    mat2 = np.zeros((n, n_classes))\n",
    "    \n",
    "    for i in range(n):\n",
    "        mat1[i, 0] = 1\n",
    "        mat2[i, 0] = 0\n",
    "        for j in range(1, n_classes):\n",
    "            mat1[i, j] = float('inf')\n",
    "    \n",
    "    # Compute variance for each subset\n",
    "    for l in range(2, n + 1):\n",
    "        s1 = s2 = w = 0\n",
    "        for m in range(1, l + 1):\n",
    "            i3 = l - m + 1\n",
    "            val = data[i3 - 1]\n",
    "            \n",
    "            s2 += val * val\n",
    "            s1 += val\n",
    "            w += 1\n",
    "            \n",
    "            v = s2 - (s1 * s1) / w\n",
    "            i4 = i3 - 1\n",
    "            \n",
    "            if i4 != 0:\n",
    "                for j in range(2, n_classes + 1):\n",
    "                    if mat1[l - 1, j - 1] >= v + mat1[i4 - 1, j - 2]:\n",
    "                        mat1[l - 1, j - 1] = v + mat1[i4 - 1, j - 2]\n",
    "                        mat2[l - 1, j - 1] = i3\n",
    "    \n",
    "    # Extract breaks\n",
    "    k = n\n",
    "    kclass = [0] * (n_classes + 1)\n",
    "    kclass[n_classes] = data[-1]\n",
    "    \n",
    "    for j in range(n_classes, 1, -1):\n",
    "        id_val = int(mat2[k - 1, j - 1] - 2)\n",
    "        kclass[j - 1] = data[id_val]\n",
    "        k = int(mat2[k - 1, j - 1] - 1)\n",
    "    \n",
    "    return kclass[1:]\n",
    "\n",
    "# 2. K-MEANS CLUSTERING\n",
    "def kmeans_breaks(data, n_classes):\n",
    "    \"\"\"\n",
    "    Use K-means clustering to find breaks\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_classes, random_state=42)\n",
    "    data_reshaped = data.values.reshape(-1, 1)\n",
    "    kmeans.fit(data_reshaped)\n",
    "    \n",
    "    # Get cluster centers and sort them\n",
    "    centers = sorted(kmeans.cluster_centers_.flatten())\n",
    "    \n",
    "    # Breaks are midpoints between centers\n",
    "    breaks = [(centers[i] + centers[i+1]) / 2 for i in range(len(centers)-1)]\n",
    "    breaks.append(data.max())\n",
    "    \n",
    "    return breaks\n",
    "\n",
    "# 3. QUANTILE-BASED (Equal Count)\n",
    "def quantile_breaks(data, n_classes):\n",
    "    \"\"\"\n",
    "    Equal count breaks using quantiles\n",
    "    \"\"\"\n",
    "    quantiles = np.linspace(0, 1, n_classes + 1)[1:]\n",
    "    breaks = [data.quantile(q) for q in quantiles]\n",
    "    return breaks\n",
    "\n",
    "# 4. EQUAL INTERVAL\n",
    "def equal_interval_breaks(data, n_classes):\n",
    "    \"\"\"\n",
    "    Equal interval breaks\n",
    "    \"\"\"\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    interval = (max_val - min_val) / n_classes\n",
    "    breaks = [min_val + interval * (i + 1) for i in range(n_classes)]\n",
    "    return breaks\n",
    "\n",
    "# 5. STANDARD DEVIATION\n",
    "def std_breaks(data, n_classes):\n",
    "    \"\"\"\n",
    "    Standard deviation breaks\n",
    "    \"\"\"\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    \n",
    "    # Create breaks at mean Â± std intervals\n",
    "    breaks = []\n",
    "    for i in range(-(n_classes // 2), (n_classes // 2) + 1):\n",
    "        if i != -(n_classes // 2):  # Skip first break\n",
    "            breaks.append(mean + i * std)\n",
    "    \n",
    "    # Adjust to data range\n",
    "    breaks = [max(data.min(), min(data.max(), b)) for b in breaks]\n",
    "    return sorted(set(breaks))\n",
    "\n",
    "# Compare all methods\n",
    "n_classes = 5\n",
    "adt_data = melted_df['ADT']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"OPTIMAL BREAK POINT ANALYSIS (n_classes={n_classes})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "methods = {\n",
    "    'Jenks Natural Breaks': jenks_breaks(adt_data, n_classes),\n",
    "    'K-Means Clustering': kmeans_breaks(adt_data, n_classes),\n",
    "    'Quantile (Equal Count)': quantile_breaks(adt_data, n_classes),\n",
    "    'Equal Interval': equal_interval_breaks(adt_data, n_classes),\n",
    "    'Standard Deviation': std_breaks(adt_data, n_classes)\n",
    "}\n",
    "\n",
    "for method_name, breaks in methods.items():\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    print(f\"  Breaks: {[f'{b:,.0f}' for b in breaks]}\")\n",
    "    \n",
    "    # Calculate how many observations in each class\n",
    "    bins = [adt_data.min() - 1] + breaks\n",
    "    labels = [f'Class {i+1}' for i in range(len(breaks))]\n",
    "    adt_data_classified = pd.cut(adt_data, bins=bins, labels=labels, include_lowest=True)\n",
    "    counts = adt_data_classified.value_counts().sort_index()\n",
    "    \n",
    "    print(f\"  Distribution:\")\n",
    "    for label, count in counts.items():\n",
    "        pct = (count / len(adt_data)) * 100\n",
    "        print(f\"    {label}: {count:>5} ({pct:>5.1f}%)\")\n",
    "\n",
    "# 6. GOODNESS OF VARIANCE FIT (GVF)\n",
    "# Measures how well the classification preserves variance\n",
    "def calculate_gvf(data, breaks):\n",
    "    \"\"\"\n",
    "    Calculate Goodness of Variance Fit\n",
    "    Higher is better (closer to 1.0)\n",
    "    \"\"\"\n",
    "    bins = [data.min() - 1] + breaks\n",
    "    classes = pd.cut(data, bins=bins, include_lowest=True)\n",
    "    \n",
    "    # Total sum of squared deviations\n",
    "    sdam = ((data - data.mean()) ** 2).sum()\n",
    "    \n",
    "    # Within-class sum of squared deviations\n",
    "    sdcm = 0\n",
    "    for class_label in classes.unique():\n",
    "        if pd.notna(class_label):\n",
    "            class_data = data[classes == class_label]\n",
    "            sdcm += ((class_data - class_data.mean()) ** 2).sum()\n",
    "    \n",
    "    gvf = (sdam - sdcm) / sdam\n",
    "    return gvf\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GOODNESS OF VARIANCE FIT (GVF) - Higher is Better\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for method_name, breaks in methods.items():\n",
    "    gvf = calculate_gvf(adt_data, breaks)\n",
    "    print(f\"{method_name:.<50} GVF = {gvf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f72cc",
   "metadata": {},
   "source": [
    "### Top k statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0bcd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the cleaned data\n",
    "melted_df = pd.read_csv('../data/traffic/adt_data.csv')\n",
    "\n",
    "# find top k busiest roads by year\n",
    "k = 25\n",
    "top_k_by_year = melted_df.groupby('Year').apply(lambda x: x.nlargest(k, 'ADT')).reset_index(drop=True)\n",
    "\n",
    "top_k_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all unique stations in the top k list\n",
    "unique_stations = top_k_by_year['Location'].unique()\n",
    "unique_stations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
